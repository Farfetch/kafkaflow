"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[5304],{28453:(e,s,r)=>{r.d(s,{R:()=>i,x:()=>a});var n=r(96540);const o={},t=n.createContext(o);function i(e){const s=n.useContext(t);return n.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function a(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),n.createElement(t.Provider,{value:s},e.children)}},46077:(e,s,r)=>{r.r(s),r.d(s,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>t,metadata:()=>a,toc:()=>h});var n=r(74848),o=r(28453);const t={sidebar_position:1},i="Consumers",a={id:"guides/consumers/consumers",title:"Consumers",description:"In this section, we will learn all about Consumers on KafkaFlow.",source:"@site/docs/guides/consumers/consumers.md",sourceDirName:"guides/consumers",slug:"/guides/consumers/",permalink:"/kafkaflow/docs/guides/consumers/",draft:!1,unlisted:!1,editUrl:"https://github.com/farfetch/kafkaflow/tree/master/website/docs/guides/consumers/consumers.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Consumers",permalink:"/kafkaflow/docs/category/consumers"},next:{title:"Add Consumers",permalink:"/kafkaflow/docs/guides/consumers/add-consumers"}},l={},h=[{value:"Message Flow",id:"message-flow",level:2},{value:"Kafka Consumer",id:"kafka-consumer",level:3},{value:"Consumer Worker Pool",id:"consumer-worker-pool",level:3},{value:"Distribution Strategy",id:"distribution-strategy",level:3},{value:"Workers",id:"workers",level:3},{value:"Middlewares",id:"middlewares",level:3},{value:"Offset Manager",id:"offset-manager",level:3},{value:"Max Poll Intervals",id:"max-poll-intervals",level:3},{value:"How it works",id:"how-it-works",level:2}];function c(e){const s={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(s.h1,{id:"consumers",children:"Consumers"}),"\n",(0,n.jsx)(s.p,{children:"In this section, we will learn all about Consumers on KafkaFlow."}),"\n",(0,n.jsxs)(s.p,{children:["Here is where KafkaFlow shines. Using KafkaFlow, you have control over how to consume the messages. Every consumer has its own ",(0,n.jsx)(s.a,{href:"#workers",children:"Workers"})," and ",(0,n.jsx)(s.a,{href:"#middlewares",children:"Middlewares"})," configuration. You can have multiple consumers consuming the same Topic with different consumer groups or one consumer with multiple Topics."]}),"\n",(0,n.jsx)(s.h2,{id:"message-flow",children:"Message Flow"}),"\n",(0,n.jsxs)(s.p,{children:["Every KafkaFlow consumer is composed of a group of components: ",(0,n.jsx)(s.a,{href:"#kafka-consumer",children:"Kafka Consumer"}),", ",(0,n.jsx)(s.a,{href:"#consumer-worker-pool",children:"Consumer Worker Pool"}),", ",(0,n.jsx)(s.a,{href:"#distribution-strategy",children:"Distribution Strategy"}),", ",(0,n.jsx)(s.a,{href:"#workers",children:"Workers"}),", ",(0,n.jsx)(s.a,{href:"#middlewares",children:"Middlewares"}),", and ",(0,n.jsx)(s.a,{href:"#offset-manager",children:"Offset Manager"}),"."]}),"\n",(0,n.jsx)(s.p,{children:"The following diagram demonstrates the flow of a message through those components."}),"\n",(0,n.jsx)(s.p,{children:(0,n.jsx)(s.img,{src:"https://user-images.githubusercontent.com/233064/98690729-24bd8000-2365-11eb-8bd0-19e6aeeaebda.jpg",alt:"Message Flow"})}),"\n",(0,n.jsx)(s.h3,{id:"kafka-consumer",children:"Kafka Consumer"}),"\n",(0,n.jsxs)(s.p,{children:["It\u2019s where the Confluent Client runs. It has a background task that fetches the messages from any topics/partitions assigned for that consumer and delivers them to the ",(0,n.jsx)(s.a,{href:"#consumer-worker-pool",children:"Consumer Worker Pool"}),". If the Confluent Consumer stops working for any reason (if a fatal exception occurs), the consumer will be recreated."]}),"\n",(0,n.jsx)(s.h3,{id:"consumer-worker-pool",children:"Consumer Worker Pool"}),"\n",(0,n.jsxs)(s.p,{children:["It orchestrates the Workers creation and destruction when the application starts, stops, and when partitions are assigned or revoked. It receives the message from ",(0,n.jsx)(s.a,{href:"#kafka-consumer",children:"Kafka Consumer"})," and uses the ",(0,n.jsx)(s.a,{href:"#distribution-strategy",children:"Distribution Strategy"})," to choose a ",(0,n.jsx)(s.a,{href:"#workers",children:"Worker"})," to enqueue the messages."]}),"\n",(0,n.jsx)(s.h3,{id:"distribution-strategy",children:"Distribution Strategy"}),"\n",(0,n.jsxs)(s.p,{children:["It\u2019s an algorithm to choose a ",(0,n.jsx)(s.a,{href:"#workers",children:"Worker"})," to process the message. The Framework has two: ",(0,n.jsx)(s.strong,{children:"BytesSum"})," and ",(0,n.jsx)(s.strong,{children:"FreeWorker"}),"."]}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsxs)(s.li,{children:["The ",(0,n.jsx)(s.strong,{children:"BytesSum"})," maintains the message order with some performance and resource penalties, ",(0,n.jsx)(s.strong,{children:"it is the default strategy"}),"."]}),"\n",(0,n.jsxs)(s.li,{children:["The ",(0,n.jsx)(s.strong,{children:"FreeWorker"})," is faster, but the message order is lost. A custom strategy can be implemented using the ",(0,n.jsx)(s.code,{children:"IDistibutionStrategy"})," interface."]}),"\n"]}),"\n",(0,n.jsxs)(s.p,{children:["You can configure the consumer strategy on the ",(0,n.jsx)(s.a,{href:"../configuration",children:"configuration"})," with the method ",(0,n.jsx)(s.code,{children:"WithWorkDistributionStrategy"}),"."]}),"\n",(0,n.jsx)(s.h3,{id:"workers",children:"Workers"}),"\n",(0,n.jsx)(s.p,{children:"Workers are responsible for processing messages when consuming. You define how many workers a consumer will have."}),"\n",(0,n.jsx)(s.p,{children:"The workers process the messages in parallel. By default (using the ByteSum distribution strategy), all messages with the same partition key are processed by the same Worker so that the message order is respected for the same partition key."}),"\n",(0,n.jsx)(s.p,{children:"Every worker has a buffer to avoid idling when many messages arrive with the same partition key for any other worker."}),"\n",(0,n.jsxs)(s.p,{children:["The buffer size should be dimensioned depending on how many messages arrive with the same partition key, on average. When the bus is requested to stop, every worker receives the stop command, and it only releases the stop call when it ends the current message and stores it in the ",(0,n.jsx)(s.a,{href:"#offset-manager",children:"Offset Manager"}),"."]}),"\n",(0,n.jsx)(s.h3,{id:"middlewares",children:"Middlewares"}),"\n",(0,n.jsxs)(s.p,{children:["It\u2019s a customizable collection of middlewares. This collection is configurable per consumer. Middlewares can be created by implementing the ",(0,n.jsx)(s.code,{children:"IMessageMiddleware"})," interface. Each consumer has its own instances of middlewares, so they are not shared between consumers but shared between ",(0,n.jsx)(s.a,{href:"#workers",children:"Workers"})," instead. You can see more information about middlewares ",(0,n.jsx)(s.a,{href:"../middlewares",children:"here"}),"."]}),"\n",(0,n.jsx)(s.h3,{id:"offset-manager",children:"Offset Manager"}),"\n",(0,n.jsx)(s.p,{children:"It is a component that receives all the offsets from the workers and orchestrates them before storing them in Kafka; this avoids an offset override when many messages are processed concurrently."}),"\n",(0,n.jsx)(s.p,{children:"Even when you choose to use the manual offset store option, you will store the offset in the OffsetManager and then store the offsets in Kafka when possible."}),"\n",(0,n.jsx)(s.admonition,{type:"warning",children:(0,n.jsx)(s.p,{children:"When the application stops, there is a big chance to have processed messages already stored in OffsetManager but not stored in Kafka. In this scenario, when the application starts again, these messages will be processed again. Your application must be prepared to deal with it."})}),"\n",(0,n.jsx)(s.h3,{id:"max-poll-intervals",children:"Max Poll Intervals"}),"\n",(0,n.jsxs)(s.p,{children:["This is the value that Kafka uses to determine the maximum amount of time allowed between calls to the consumers' poll method before the process is considered as failed. By default, this has a value of 300 seconds, but it may be adjusted with the ",(0,n.jsx)(s.code,{children:"WithMaxPollInterval"})," configuration."]}),"\n",(0,n.jsx)(s.p,{children:"If the maximum time is exceeded, the consumer will go offline, but the workers will continue to run in the background, leading to an increasing read lag until the application goes down."}),"\n",(0,n.jsxs)(s.p,{children:["Further information can be found in the official ",(0,n.jsx)(s.a,{href:"https://docs.confluent.io/platform/current/clients/consumer.html#message-handling",children:"documentation"}),"."]}),"\n",(0,n.jsx)(s.h2,{id:"how-it-works",children:"How it works"}),"\n",(0,n.jsxs)(s.p,{children:["The following animation shows a consumer listening to one topic with two ",(0,n.jsx)(s.a,{href:"#workers",children:"Workers"})," having a buffer size of 2 using the ",(0,n.jsx)(s.strong,{children:"BytesSum"})," distribution strategy."]}),"\n",(0,n.jsx)(s.p,{children:(0,n.jsx)(s.img,{src:"https://user-images.githubusercontent.com/233064/98690723-22f3bc80-2365-11eb-8453-04349abb103c.gif",alt:"consumer-animation"})})]})}function d(e={}){const{wrapper:s}={...(0,o.R)(),...e.components};return s?(0,n.jsx)(s,{...e,children:(0,n.jsx)(c,{...e})}):c(e)}}}]);